import os
import base64
import json
import time
from tqdm import tqdm
from multiprocessing import Pool, Manager
from openai import OpenAI, RateLimitError, APIError

def get_client_model(model_path, api_key, base_url):
    """Initializes the OpenAI client."""
    assert api_key is not None, "API key is required for using OpenAI"
    assert model_path is not None, "Model name is required for using OpenAI"
    client = OpenAI(api_key=api_key, base_url=base_url)
    model = model_path
    return client, model

def generate_response(client, model, image_paths, query, media_type="image/jpeg"):
    """
    Generates a response from the OpenAI API using the provided client and model.
    """
    def encode_image(image_path):
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

    # Encode images to base64 strings
    base64_images = [encode_image(image_path) for image_path in image_paths]

    messages = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": query}
            ]
        }
    ]

    image_content = [
        {
            "type": "image_url",
            "image_url": {"url": f"data:{media_type};base64,{image}"}
        }
        for image in base64_images
    ]
    messages[0]["content"].extend(image_content)

    max_retries = 5
    retries = 0
    while retries < max_retries:
        try:
            # Send the request using the openai library
            response = client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=4096,
                temperature=0.0,
                top_p=1.0,
                seed=23
            )
            # Extract and return the message content
            if response.choices:
                return response.choices[0].message.content
            else:
                raise ValueError("Invalid response structure: 'choices' field is missing or empty.")

        except RateLimitError as e:
            backoff_factor = 2
            wait_time = backoff_factor ** retries
            print(f"Rate limited. Retrying in {wait_time} seconds...")
            time.sleep(wait_time)
            retries += 1

    return None # Return None if all retries fail


def process_file(file_name, reference_folder, generate_folder, model, client, result_list, progress_lock):
    """
    Processes a single file by comparing a reference image with an AI-generated image.
    """
    file_path = os.path.join(reference_folder, file_name)
    png_file_path = os.path.join(generate_folder, file_name)

    if not os.path.exists(file_path) or not os.path.exists(png_file_path):
        print(f"Warning: Missing PNG files for {file_name}. Skipping.")
        return

    try:
        prompt = """
You are an excellent judge at evaluating visualization chart plots. The first image (reference
image) is created using ground truth matplotlib code, and the second image (AI-generated
image) is created using matplotlib code generated by an AI assistant. Your task is to score
how well the AI-generated plot matches the ground truth plot.
### Scoring Methodology:
The AI-generated image’s score is based on the following criteria, totaling a score out of 100
points:
1. Chart Types (20 points): Does the AI-generated image include all chart types present in
the reference image (e.g., line charts, bar charts, etc.)?
2. Layout (10 points): Does the arrangement of subplots in the AI-generated image match the
reference image (e.g., number of rows and columns)?
3. Text Content (20 points): Does the AI-generated image include all text from the reference
image (e.g., titles, annotations, axis labels), excluding axis tick labels?
4. Data (20 points): How accurately do the data trends in the AI-generated image resemble
those in the original image and is the number of data groups the same as in the reference
image?
5. Style (20 points): Does the AI-generated image match the original in terms of colors (line
colors, fill colors, etc.), marker types (point shapes, line styles, etc.), legends, grids, and other
stylistic details?
6. Clarity (10 points): Is the AI-generated image clear and free of overlapping elements?
### Evaluation:
Compare the two images head to head and provide a detailed assessment. Use the following
format for your response:
—
Comments:
- Chart Types: ${your comment and subscore}
- Layout: ${your comment and subscore}
- Text Content: ${your comment and subscore}
- Data: ${your comment and subscore}
- Style: ${your comment and subscore}
- Clarity: ${your comment and subscore}
Score: ${your final score out of 100}
—
Please use the above format to ensure the evaluation is clear and comprehensive.
        """
        
        response = generate_response(
            client=client,
            model=model,
            image_paths=[file_path, png_file_path],
            query=prompt
        )
        
        result = {"file_name": file_name, "response": response}
        result_list.append(result)
        # print(f"Processed {file_name} successfully.")

    except Exception as e:
        print(f"Error processing file {file_name}: {e}")
        result = {"file_name": file_name, "response": None, "error": str(e)}
        result_list.append(result)

    # Signal that one file is done to update the progress bar
    with progress_lock:
        result_list.append("done_marker")

def process_files_in_parallel(reference_folder, generate_folder, model, client, output_file, num_processes):
    """
    Processes all PNG files in a directory in parallel and saves the results.
    """
    with Manager() as manager:
        result_list = manager.list()
        progress_lock = manager.Lock()
        
        png_files = [f for f in os.listdir(reference_folder) if f.endswith(".png")]
        
        pool_args = [(file_name, reference_folder, generate_folder, model, client, result_list, progress_lock) for file_name in png_files]

        with Pool(processes=num_processes) as pool:
            # Use tqdm to create a progress bar
            with tqdm(total=len(png_files), desc="Processing files", unit="file") as pbar:
                for _ in pool.starmap(process_file, pool_args):
                    pbar.update()

        # Filter out progress markers before writing to the file
        final_results = [item for item in result_list if item != "done_marker"]

        with open(output_file, "w") as out_f:
            for result in final_results:
                out_f.write(json.dumps(result) + "\n")

        print(f"Results saved to {output_file}")


# Example usage
if __name__ == "__main__":
    # Your API key, model, and the custom base URL
    API_KEY = os.environ.get("OPENAI_API_KEY") 
    BASE_URL = os.environ.get("OPENAI_BASE_URL", "https://api.openai.com/v1")
    MODEL_NAME = 'gpt-4o'
    NUM_PROCESSES = 20
    # Initialize the OpenAI client
    client, model = get_client_model(MODEL_NAME, API_KEY, BASE_URL)
    
    model_list = ['InternVL2_5-8B']
    for model in model_list:
        OUTPUT_FILE = f"eval_results/chart_level/{model.replace('-','_')}_results.jsonl"
        REFERENCE_FOLDER = "chartedit/reference/figs"
        GENERATE_FOLDER = f"results/{model.replace('-','_')}/figs_inter"

        # Ensure output directory exists
        os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
        
        print(f"Starting processing for model: {model}")
        process_files_in_parallel(REFERENCE_FOLDER, GENERATE_FOLDER, model, client, OUTPUT_FILE, NUM_PROCESSES)